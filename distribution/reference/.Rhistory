paste(length(which(transcript_num_table_gather_entrez$group ==  "high" &
transcript_num_table_gather_entrez$DB ==  "TxDb")))))
p + geom_text(data = ann_text_entrez, aes(x, y, label = labs, group = NULL), size = 8)
# merging datasets by Ensembl ID
transcript_num_table_ensembl <- full_join(org_transcript_num_table_ensembl, EnsDb_transcript_num_table_ensembl, by = "Ensembl")
# gather for plotting
transcript_num_table_gather_ensembl <- transcript_num_table_ensembl %>%
gather(DB, count, orgDb:EnsDb)
# How many counts are NA?
sapply(transcript_num_table_gather_ensembl, function(x) sum(is.na(x)))
# removing rows with NA counts
transcript_num_table_gather_ensembl <- transcript_num_table_gather_ensembl[!is.na(transcript_num_table_gather_ensembl$count), ]
# because there are only a handful of genes with many transcripts, they can't be plotted together with genes with few transcripts
# separating them in high and low
transcript_num_table_gather_ensembl$group <- ifelse(transcript_num_table_gather_ensembl$count > 25, "high", "low")
# setting factor levels
f = c("low", "high")
transcript_num_table_gather_ensembl <- within(transcript_num_table_gather_ensembl, group <- factor(group, levels = f))
p <- ggplot(data = transcript_num_table_gather_ensembl, aes(as.numeric(count))) +
geom_histogram(fill = "deepskyblue4") +
my_theme() +
labs(title = "Histogram of number of transcripts per gene (Ensembl ID)",
x = "Number of transcripts per gene", y = "Count") +
facet_wrap(DB ~ group, scales = "free", ncol = 2)
ann_text_ensembl <- data.frame(x = c(10, 75, 10, 100),
y = c(30000, 100, 15000, 100),
group = rep(c("low", "high"), 4),
DB = rep(c("EnsDb", "orgDb"), each = 2),
labs = c(paste(length(which(transcript_num_table_gather_ensembl$group ==  "low" &
transcript_num_table_gather_ensembl$DB ==  "EnsDb"))),
paste(length(which(transcript_num_table_gather_ensembl$group ==  "high" &
transcript_num_table_gather_ensembl$DB ==  "EnsDb"))),
paste(length(which(transcript_num_table_gather_ensembl$group ==  "low" &
transcript_num_table_gather_ensembl$DB ==  "orgDb"))),
paste(length(which(transcript_num_table_gather_ensembl$group ==  "high" &
transcript_num_table_gather_ensembl$DB ==  "orgDb")))))
p + geom_text(data = ann_text_ensembl, aes(x, y, label = labs, group = NULL), size = 8)
# for comparison replacing NAs with 0
transcript_num_table_ensembl_NAtozero <- transcript_num_table_ensembl
transcript_num_table_ensembl_NAtozero[is.na(transcript_num_table_ensembl_NAtozero)] <- 0
transcript_num_table_entrez_NAtozero <- transcript_num_table_entrez
transcript_num_table_entrez_NAtozero[is.na(transcript_num_table_entrez_NAtozero)] <- 0
library(ggrepel)
p1 <- ggplot(transcript_num_table_ensembl_NAtozero, aes(x = orgDb, y = EnsDb)) +
geom_abline(linetype="dashed") +
geom_point(colour = "deepskyblue4", alpha = 0.3) +
my_theme() +
geom_smooth(size = 1, color = "black") +            # Add a loess smoothed fit curve with confidence region
labs(title = "Number of transcripts per Ensembl ID") +
geom_text_repel(data = subset(transcript_num_table_ensembl_NAtozero, orgDb > 140 | EnsDb > 150), aes(label = Ensembl))
p2 <- ggplot(transcript_num_table_entrez_NAtozero, aes(x = orgDb, y = TxDb)) +
geom_abline(linetype="dashed") +
geom_point(colour = "deepskyblue4", alpha = 0.3) +
my_theme() +
geom_smooth(size = 1, color = "black") +
labs(title = "Number of transcripts per Entrez ID") +
geom_text_repel(data = subset(transcript_num_table_entrez_NAtozero, orgDb > 100 | TxDb > 200), aes(label = Entrez))
p3 <- ggplot(transcript_num_table_entrez_NAtozero, aes(x = orgDb, y = EnsDb)) +
geom_abline(linetype="dashed") +
geom_point(colour = "deepskyblue4", alpha = 0.3) +
my_theme() +
geom_smooth(size = 1, color = "black") +
labs(title = "Number of transcripts per Entrez ID") +
geom_text_repel(data = subset(transcript_num_table_entrez_NAtozero, orgDb > 100 | EnsDb > 900), aes(label = Entrez))
p4 <- ggplot(transcript_num_table_entrez_NAtozero, aes(x = TxDb, y = EnsDb)) +
geom_abline(linetype="dashed") +
geom_point(colour = "deepskyblue4", alpha = 0.3) +
my_theme() +
geom_smooth(size = 1, color = "black") +
labs(title = "Number of transcripts per Entrez ID") +
geom_text_repel(data = subset(transcript_num_table_entrez_NAtozero, TxDb > 150 | EnsDb > 900), aes(label = Entrez))
library(gridExtra)
library(grid)
library(gridExtra)
library(grid)
install.packages("prettyR")
install.packages('IRkernel',dep=TRUE)
IRkernel::installspec()  # to register the kernel in the current R installation
install.packages("IRkernel", dep = TRUE)
install.packages("IRkernel", dep = TRUE)
install.packages("IRkernel", dep = TRUE)
install.packages('IRkernel',dep=TRUE)
IRkernel::installspec()  # to register the kernel in the current R installation
install.packages('devtools',dep=TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
2+2
2+2
x
x=1
x
x = x+10
x
x = x+10
x
x = x+10
x
x = x+10
x
x = x+10
x
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
2+2
x=1
x
x = x+10
x
x = x+10
x
hist(rnorm(1000))
hist(rnorm(100, mean = 2, sd = .2))
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
2+2
x=1
x
x = x+10
x
hist(rnorm(1000))
hist(rnorm(100, mean = 2, sd = .2))
---
title: "Mon premier document"
output:
html_document: default
pdf_document: default
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## R Markdown
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r cars}
summary(cars)
```
## Including Plots
You can also embed plots, for example:
```{r pressure, echo=FALSE}
plot(pressure)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
## Ma propre section
```{r}
2+2
x=1
x
```
```{r}
x = x+10
x
```
```{r}
hist(rnorm(1000))
```
```{r}
hist(rnorm(100, mean = 2, sd = .2))
```
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
2+2
x=1
x
x = x+10
x
hist(rnorm(1000))
hist(rnorm(100, mean = 2, sd = .2))
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
2+2
x=1
x
x = x+10
x
hist(rnorm(1000))
hist(rnorm(100, mean = 2, sd = .2))
unlink('Documents/these_nguillaudeux/Archives_docs/Formations/MOOC_reproductibilite/mooc-rr/module2/docu1_cache', recursive = TRUE)
# Install core Bioconductor packages
if (!requireNamespace("BiocManager"))
install.packages("BiocManager")
BiocManager::install()
# install biomartr 0.8.0
install.packages("biomartr", dependencies = TRUE)
# Install core Bioconductor packages
if (!requireNamespace("BiocManager"))
install.packages("BiocManager")
BiocManager::install()
# Install package dependencies
BiocManager::install("Biostrings", version = "3.8")
BiocManager::install("biomaRt", version = "3.8")
BiocManager::install("biomaRt", version = "3.8")
data_url = "https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/HistData/Wheat.csv"
data_url
data_url = "https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/HistData/Wheat.csv"
data_url = read.csv('/home/niguilla/Documents/these_nguillaudeux/Archives_docs/Formations/MOOC_reproductibilite/mooc-rr/mooc-rr/module3/eval_pairs/Wheat.csv')
data_url = read.csv('/home/niguilla/Documents/these_nguillaudeux/Archives_docs/Formations/MOOC_reproductibilite/mooc-rr/mooc-rr/eval_pairs/Wheat.csv')
data_url
Wheat = read.csv('/home/niguilla/Documents/these_nguillaudeux/Archives_docs/Formations/MOOC_reproductibilite/mooc-rr/mooc-rr/eval_pairs/Wheat.csv')
Wheat
data(Wheat)
# convenience function to fill area under a curve down to a minimum value
fillpoly <- function(x,y, low=min(y),  ...) {
n <- length(x)
polygon( c(x, x[n], x[1]), c(y, low, low), ...)
}
# For best results, this graph should be viewed with width ~ 2 * height
# Note use of type='s' to plot a step function for Wheat
#   and panel.first to provide a background grid()
#     The curve for Wages is plotted after the polygon below it is filled
with(Wheat, {
plot(Year, Wheat, type="s", ylim=c(0,105),
ylab="Price of the Quarter of Wheat (shillings)",
panel.first=grid(col=gray(.9), lty=1))
fillpoly(Year, Wages, low=0, col="lightskyblue", border=NA)
lines(Year, Wages, lwd=3, col="red")
})
# Lecture du tableau de l'ensemble des blocs d'exons
data <- read.table("nb_reads_mapped_tissue.csv", header = TRUE, sep = "\t", dec=',')
head(data)
summary(data)
data[1]
length(data)
cbind(data, total = rowSums(data[2:16]))
hist(data[2:16])
data_cp <- data[2:16]
summary(data_cp)
barplot(data$ADRENALGLAND, data$BLOOD, data$BRAIN, xlab(data$Junctions))
ggplot(data) +
geom_col(aes(x = data$Junctions, y=c(data$ADRENALGLAND)))
ggplot(gather(data_cp, cols, value), aes(x = value)) +
geom_histogram(binwidth = 20) + facet_grid(.~cols)
for (col in 2:ncol(data)) {
hist(data[,col], breaks=10)
}
ggplot(gather(mtcars), aes(value)) +
geom_histogram(bins = 10) +
facet_wrap(~key, scales = 'free_x')
data_not_null = read.table("nonull_sum_all.csv", h=T, sep='\t')
summary(data_not_null)
p <- ggplot(data_not_null, aes(x=species, y=sum, fill=species)) +
geom_boxplot()
p+scale_fill_manual(values=c("pink", "#56B4E9", "grey"))
p + ggtitle("Distribution du nombre de reads alignés sur les jonctions testées") +
xlab("Espèces") +
ylab("Nombre de reads")
#install.packages("ggplot2")
#install.packages("cowplot")
library("ggplot2")
library("cowplot")
# read file
data = read.table("nb_reads_mapped_tissue_hs.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
setwd("~/Documents/Software/gtf_validator_of_cgalcode_prediction/distribution")
#install.packages("ggplot2")
#install.packages("cowplot")
library("ggplot2")
library("cowplot")
# read file
data = read.table("nb_reads_mapped_tissue_hs.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
#data_null = read.table("null_sum.csv", h=T, sep='\t')
data_not_null = read.table("nonull_sum_hs.csv", h=T, sep='\t')
summary(data_not_null)
p <- ggplot(data_not_null, aes(x=data_not_null$sum)) +
geom_density()
p + ggtitle("Distribution du nombre de reads alignés sur les jonctions testées chez l'humain") +
xlab("Nombre de reads alignés sur les jonctions testées") +
ylab("Fréquence")
boxplot(data_not_null$sum)
hist(data_not_null$sum, nclass=10)
hist(data_not_null$sum, br = c(0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000, 1050, 1100, 1150, 1200, 1250, 1300))
# read file
data = read.table("reference/nb_reads_mapped_tissue_hs.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
# write files
#write.table(data[data$sum==0,],"null_sum.csv", sep='\t')
write.table(data[data$sum>0,],"nonull_sum_hs.csv", sep='\t')
# read file
data = read.table("nb_reads_mapped_tissue_hs.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
# write files
#write.table(data[data$sum==0,],"null_sum.csv", sep='\t')
write.table(data[data$sum>0,],"nonull_sum_hs.csv", sep='\t')
#data_null = read.table("null_sum.csv", h=T, sep='\t')
data_not_null = read.table("nonull_sum_hs.csv", h=T, sep='\t')
summary(data_not_null)
setwd("~/Documents/Software/gtf_validator_of_cgalcode_prediction/distribution/reference")
# read file
data = read.table("reference/nb_reads_mapped_tissue_hs.csv", header = T, sep='\t')
# read file
data = read.table("nb_reads_mapped_tissue_hs.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
# write files
#write.table(data[data$sum==0,],"null_sum.csv", sep='\t')
write.table(data[data$sum>0,],"nonull_sum_hs.csv", sep='\t')
#data_null = read.table("null_sum.csv", h=T, sep='\t')
data_not_null = read.table("nonull_sum_hs.csv", h=T, sep='\t')
summary(data_not_null)
p <- ggplot(data_not_null, aes(x=data_not_null$sum)) +
geom_density()
p + ggtitle("Distribution du nombre de reads alignés sur les jonctions testées chez l'humain") +
xlab("Nombre de reads alignés sur les jonctions testées") +
ylab("Fréquence")
boxplot(data_not_null$sum)
hist(data_not_null$sum, nclass=10)
hist(data_not_null$sum, br = c(0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000, 1050, 1100, 1150, 1200, 1250, 1300))
plot(data_not_null$sum)
hist(data_not_null$sum)
# read file
data = read.table("nb_reads_mapped_tissue_hs.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
# write files
#write.table(data[data$sum==0,],"null_sum.csv", sep='\t')
write.table(data[data$sum>0,],"nonull_sum_hs.csv", sep='\t')
#data_null = read.table("null_sum.csv", h=T, sep='\t')
data_not_null = read.table("nonull_sum_hs.csv", h=T, sep='\t')
summary(data_not_null)
p <- ggplot(data_not_null, aes(x=data_not_null$sum)) +
geom_density()
p + ggtitle("Distribution du nombre de reads alignés sur les jonctions testées chez l'humain") +
xlab("Nombre de reads alignés sur les jonctions testées") +
ylab("Fréquence")
# read file
data = read.table("nb_reads_mapped_tissue_mm.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
# write files
#write.table(data[data$sum==0,],"null_sum.csv", sep='\t')
write.table(data[data$sum>0,],"nonull_sum_mm.csv", sep='\t')
#data_null = read.table("null_sum.csv", h=T, sep='\t')
data_not_null = read.table("nonull_sum_mm.csv", h=T, sep='\t')
summary(data_not_null)
p <- ggplot(data_not_null, aes(x=data_not_null$sum)) +
geom_density()
p + ggtitle("Distribution du nombre de reads alignés sur les jonctions testées chez l'humain") +
xlab("Nombre de reads alignés sur les jonctions testées") +
ylab("Fréquence")
# read file
data = read.table("nb_reads_mapped_tissue_clf.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
# write files
#write.table(data[data$sum==0,],"null_sum.csv", sep='\t')
write.table(data[data$sum>0,],"nonull_sum_clf.csv", sep='\t')
#data_null = read.table("null_sum.csv", h=T, sep='\t')
data_not_null = read.table("nonull_sum_clf.csv", h=T, sep='\t')
summary(data_not_null)
p <- ggplot(data_not_null, aes(x=data_not_null$sum)) +
geom_density()
p + ggtitle("Distribution du nombre de reads alignés sur les jonctions testées chez l'humain") +
xlab("Nombre de reads alignés sur les jonctions testées") +
ylab("Fréquence")
data  = read.table("nonull_sum_all.csv", sep='\t')
summary(data)
data  = read.table("nonull_sum_all.csv", sep='\t', header=TRUE)
summary(data)
table(data$species)
table(data$sum)
table(data$sum, data$species)
summary(data_not_null)
table(data$sum, data$species)
table(data$species, data$sum)
table(data$sum, data$species)
tableau <- table(data$sum, data$species)
print(tableau)
addmargins(tableau)
prop.table(tableau)
prop.table(tableau,1)
prop.table(tableau,2)
prop.table(tableau,2)
prop.table(tableau,1)
prop.table(tableau,2)
addmargins(prop.table(tableau,2) )
tableau2 <- addmargins(prop.table(tableau,2) )
View(tableau2)
# read file
data = read.table("nb_reads_mapped_tissue_clf.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
# write files
#write.table(data[data$sum==0,],"null_sum.csv", sep='\t')
write.table(data[data$sum>0,],"nonull_sum_clf.csv", sep='\t')
#data_null = read.table("null_sum.csv", h=T, sep='\t')
data_not_null = read.table("nonull_sum_clf.csv", h=T, sep='\t')
summary(data_not_null)
p <- ggplot(data_not_null, aes(x=data_not_null$sum)) +
geom_density()
# read file
data = read.table("nb_reads_mapped_tissue_clf.csv", header = T, sep='\t')
# read file
data = read.table("nb_reads_mapped_tissue_clf.csv", header = T, sep='\t')
setwd("~/Documents/Software/gtf_validator_of_cgalcode_prediction/distribution/reference")
# read file
data = read.table("nb_reads_mapped_tissue_clf.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
# write files
#write.table(data[data$sum==0,],"null_sum.csv", sep='\t')
write.table(data[data$sum>0,],"nonull_sum_clf.csv", sep='\t')
#data_null = read.table("null_sum.csv", h=T, sep='\t')
data_not_null = read.table("nonull_sum_clf.csv", h=T, sep='\t')
summary(data_not_null)
# read file
data = read.table("nb_reads_mapped_tissue_hs.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
# write files
#write.table(data[data$sum==0,],"null_sum.csv", sep='\t')
write.table(data[data$sum>0,],"nonull_sum_hs.csv", sep='\t')
#data_null = read.table("null_sum.csv", h=T, sep='\t')
data_not_null = read.table("nonull_sum_hs.csv", h=T, sep='\t')
summary(data_not_null)
p <- ggplot(data_not_null, aes(x=data_not_null$sum)) +
geom_density()
p + ggtitle("Distribution du nombre de reads alignés sur les jonctions testées chez l'humain") +
xlab("Nombre de reads alignés sur les jonctions testées") +
ylab("Fréquence")
# read file
data = read.table("nb_reads_mapped_tissue_mm.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
# write files
#write.table(data[data$sum==0,],"null_sum.csv", sep='\t')
write.table(data[data$sum>0,],"nonull_sum_mm.csv", sep='\t')
#data_null = read.table("null_sum.csv", h=T, sep='\t')
data_not_null = read.table("nonull_sum_mm.csv", h=T, sep='\t')
summary(data_not_null)
p <- ggplot(data_not_null, aes(x=data_not_null$sum)) +
geom_density()
p + ggtitle("Distribution du nombre de reads alignés sur les jonctions testées chez l'humain") +
xlab("Nombre de reads alignés sur les jonctions testées") +
ylab("Fréquence")
# read file
data = read.table("nb_reads_mapped_tissue_clf.csv", header = T, sep='\t')
summary(data)
# sum by rows
data$sum = apply(data[,2:ncol(data)],1,sum)
summary(data)
# write files
#write.table(data[data$sum==0,],"null_sum.csv", sep='\t')
write.table(data[data$sum>0,],"nonull_sum_clf.csv", sep='\t')
#data_null = read.table("null_sum.csv", h=T, sep='\t')
data_not_null = read.table("nonull_sum_clf.csv", h=T, sep='\t')
summary(data_not_null)
p <- ggplot(data_not_null, aes(x=data_not_null$sum)) +
geom_density()
p + ggtitle("Distribution du nombre de reads alignés sur les jonctions testées chez l'humain") +
xlab("Nombre de reads alignés sur les jonctions testées") +
ylab("Fréquence")
data  = read.table("nonull_sum_all.csv", sep='\t', header=TRUE)
summary(data)
tableau <- table(data$sum, data$species)
print(tableau)
addmargins(tableau)
prop.table(tableau)
tableau2 <- addmargins(prop.table(tableau,2) )
View(tableau2)
View(tableau2)
hist(tableau)
barplot(tableau)
boxplot(tableau)
plot(tableau)
hist(tableau)
hist(tableau)
summary(data)
tableau <- table(data$sum, data$species)
#hist(tableau)
print(tableau)
addmargins(tableau)
#hist(tableau)
print(tableau)
